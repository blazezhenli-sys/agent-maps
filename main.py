# main.py

import re
import json
import os
import requests
import dotenv
from langchain_openai import ChatOpenAI
from map_tool import get_city_geojson
from googletrans import Translator

dotenv.load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Environment
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SERPER_API_KEY = os.getenv("SERPER_API_KEY")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

if not SERPER_API_KEY:
    raise ValueError("SERPER_API_KEY not set")

if not OPENROUTER_API_KEY:
    raise ValueError("OPENROUTER_API_KEY not set")

translator = Translator()

llm = ChatOpenAI(
    model="stepfun/step-3.5-flash:free",
    temperature=0,
    openai_api_key=OPENROUTER_API_KEY,
    openai_api_base="https://openrouter.ai/api/v1",
)

TIME_FILTER = "113å¹´ OR 114å¹´ OR 2024 OR 2025"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Topic Config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TOPIC_CONFIG = {
    "cleanliness": {
        "keywords": "æ¸…æ½”éšŠ OR è³‡æºå›æ”¶ç‡ OR å›æ”¶è€ƒæ ¸ OR è©•æ¯”æˆç¸¾ OR æ’å OR ç¸¾æ•ˆ OR ä¹¾æ·¨ OR åƒåœ¾ OR è¡›ç”Ÿ OR åƒåœ¾å±± OR å›æ”¶ç¸¾æ•ˆ",
        "sites": [
            "site:epa.gov.tw",
            "site:moenv.gov.tw",
            "site:udn.com",
            "site:ltn.com.tw",
            "site:chinatimes.com",
            "site:ettoday.net",
            "site:g0v.tw",
            "site:nownews.com",
            "site:thenewslens.com",
            "site:storm.mg",
            "site:newtalk.tw",
            "site:cna.com.tw",
            "site:ptt.cc",
            "site:mobile01.com",
            "site:news.google.com.tw"
        ]
    },
    "air quality": {
        "keywords": "ç©ºæ°£å“è³ª OR PM2.5 OR AQI OR ç©ºæ±¡ OR ç›£æ¸¬ç«™ OR æ±¡æŸ“ OR ç©ºæ°£ OR ç©ºå“",
        "sites": [
            "site:airtw.moenv.gov.tw",
            "site:moenv.gov.tw",
            "site:epa.gov.tw",
            "site:udn.com",
            "site:ltn.com.tw",
            "site:ettoday.net",
            "site:storm.mg",
            "site:ptt.cc",
            "site:mobile01.com"
        ]
    },
    "safety": {
        "keywords": "æ²»å®‰ OR çŠ¯ç½ªç‡ OR åˆ‘æ¡ˆ OR è­¦å±€ OR å ±æ¡ˆ OR å®‰å…¨ OR çŠ¯ç½ª",
        "sites": [
            "site:police.gov.tw",
            "site:npa.gov.tw",
            "site:udn.com",
            "site:ltn.com.tw",
            "site:ettoday.net",
            "site:chinatimes.com",
            "site:ptt.cc",
            "site:mobile01.com"
        ]
    },
    "cost of living": {
        "keywords": "æˆ¿åƒ¹ OR ç§Ÿé‡‘ OR ç”Ÿæ´»æˆæœ¬ OR æˆ¿ç§Ÿ OR æˆ¿å¸‚ OR ç‰©åƒ¹ OR ç”Ÿæ´»è²» OR å¯¦åƒ¹ç™»éŒ„ OR æ¯åª",
        "sites": [
            "site:591.com.tw",
            "site:houseprice.tw",
            "site:catking.tw",
            "site:numbeo.com",
            "site:mobile01.com",
            "site:ptt.cc",
            "site:udn.com",
            "site:ltn.com.tw"
        ]
    },
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Search
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def serper_search(query):
    url = "https://google.serper.dev/search"
    payload = json.dumps({"q": query, "num": 8})

    headers = {
        "X-API-KEY": SERPER_API_KEY,
        "Content-Type": "application/json"
    }

    response = requests.post(url, headers=headers, data=payload)
    response.raise_for_status()
    results = response.json()

    parts = []

    if "answerBox" in results:
        parts.append(results["answerBox"].get("answer", ""))

    for r in results.get("organic", [])[:6]:
        parts.append(f"{r.get('title', '')} - {r.get('snippet', '')}")

    return "\n\n".join(parts)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GeoJSON Handling
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ensure_geojson(city, topic):
    """
    Ensures GeoJSON file exists for city and that it contains features.
    """
    geo_file = f"{city}_{topic}_map.geojson"

    if not os.path.exists(geo_file):
        geojson_data_raw = get_city_geojson(city)
        if geojson_data_raw and geojson_data_raw[0]:
            geojson_data = geojson_data_raw[0]

            # Validate
            if not isinstance(geojson_data, dict):
                raise ValueError("GeoJSON is not a dictionary")
            if "features" not in geojson_data or not geojson_data["features"]:
                raise ValueError("GeoJSON has no features")

            # Save validated GeoJSON
            with open(geo_file, "w") as f:
                json.dump(geojson_data, f, indent=4)
        else:
            raise ValueError("Failed to fetch GeoJSON")

    return geo_file

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Scoring Engine (Single District)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def score_district(city, topic, district, logger=print):
    """
    Scores ONE district and returns float.
    Uses cached value if available.
    """

    data_file = f"{city}_{topic}_data.json"

    # â”€â”€â”€â”€â”€ Check Cache â”€â”€â”€â”€â”€
    if os.path.exists(data_file):
        with open(data_file) as f:
            existing = json.load(f)
            if district in existing:
                logger("ğŸ“‚ Using cached score")
                return existing[district]
    else:
        existing = {}

    logger(f"ğŸ” Searching data for {district}...")

    config = TOPIC_CONFIG.get(topic.lower(), {"keywords": topic, "sites": []})
    topic_kws = config["keywords"]
    topic_sites = " OR ".join(config["sites"])

    query = (
        f"{district} {topic_kws} "
        f"{TIME_FILTER} "
        f"{topic_sites}"
    )

    area_info = serper_search(query)

    logger("ğŸ¤– Running LLM scoring...")

    score_prompt = f"""
You are an urban analyst in {city}.

DATA:
{area_info}

TASK:
Rate "{topic}" of {district} from 0.00 (very poor) to 1.00 (excellent).

Use two decimal places strictly.
Return ONLY a number like 0.52.
"""

    score_prompt_zh = translator.translate(score_prompt, dest='zh-tw').text
    score_reply = llm.invoke(score_prompt_zh).content.strip()

    match = re.search(r"\d+\.\d{2}", score_reply)
    score = float(match.group()) if match else 0.50

    logger(f"âœ… Score: {score:.2f}")

    # â”€â”€â”€â”€â”€ Save Cache â”€â”€â”€â”€â”€
    existing[district] = score
    with open(data_file, "w") as f:
        json.dump(existing, f, indent=4)

    return score